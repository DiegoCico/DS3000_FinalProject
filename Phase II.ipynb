{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase II: Data Curation, Exploratory Analysis and Plotting\n",
    "## Stock Market Predictor\n",
    "\n",
    "### Names: Diego Cicotoste, Ariv Ahuja, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction \n",
    "\n",
    "How does the stock market work? how can you predict the stock market? what tools can you use? The stock market can seem complex and unpredictable, some would even say gambeling. One of the hardest challenges is making educated or informed decisions. The goal of this project is to tackle the uncertainty and help, stock traders make better decision on wether a stock is tradable or not. Wether to buy or sell. I would use past historical trends to make educated predictions on how the stock market would react."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Data Retrieval**  \n",
    "- We used the **`yfinance` API** to retrieve daily historical **Open, High, Low, Close (OHLC)** prices and **volume data** for **S&P 500 stocks**, focusing on **Amazon (AMZN)** for the **past year**.\n",
    "- The retrieved data includes essential market metrics that will serve as the foundation for feature engineering.\n",
    "- We used **`NewsAPI`** to get article data on the stock\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Data Cleaning and Processing**\n",
    "\n",
    "#### **Handling Missing Data**  \n",
    "- No data was missing after inspection\n",
    "\n",
    "#### **Feature Engineering: Technical Indicators**  \n",
    "We calculated several key **technical indicators** to enrich the dataset:\n",
    "  - **RSI (Relative Strength Index)**: Momentum indicator over 14 days.\n",
    "  - **VWAP (Volume Weighted Average Price)**: Measures the average trading price weighted by volume.\n",
    "  - **EMA (Exponential Moving Average)**: Captures the smoothed trend over 20 days.\n",
    "  - **ADX (Average Directional Index)**: Quantifies trend strength.\n",
    "\n",
    "#### **More Features: Sentiment Analysis from News Articles**  \n",
    "- We fetched relevant **news articles** using **NewsAPI** for the same period as the stock data.\n",
    "- **VADER Sentiment Analysis** was used to calculate **compound sentiment scores** for each article.\n",
    "- Sentiment scores were **aggregated by date** to align with the stock OHLC data.\n",
    "\n",
    "#### **Data Alignment and Merging**  \n",
    "- We ensured **alignment** between **OHLC data, technical indicators, log returns, and sentiment scores** using date-based indices.\n",
    "- The combined DataFrame was prepared, with all relevant features available for further analysis and modeling.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Visualization of the Cleaned Data**\n",
    "\n",
    "We visualized the **cleaned and processed dataset** to understand key trends and patterns:\n",
    "\n",
    "1. **Price Trends and Indicators**:\n",
    "   - **OHLC Candlestick Plots**: Show stock price movements.\n",
    "   - **Overlaying VWAP and EMA**: To track trends and identify support/resistance levels.\n",
    "   - **RSI and ADX Line Plots**: Visualize momentum and trend strength over time.\n",
    "\n",
    "2. **Volume Analysis**:\n",
    "   - **Normalized Volume**: Visualized to detect significant changes in trading activity.\n",
    "\n",
    "3. **Sentiment Trends**:\n",
    "   - **Sentiment Score Line Chart**: Displays how public sentiment fluctuates over time.\n",
    "   - **Overlay of Sentiment with Stock Price**: To observe correlations between sentiment and price movements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "def get_stock_data(symbol: str, period: str, interval: str = '1d') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Retrieve stock price data for a given symbol, time period, and interval.\n",
    "    Returns the stock prices as a pandas DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        symbol (str): The ticker symbol of the stock (e.g., 'AAPL').\n",
    "        period (str): The period to retrieve data (e.g., '1y', '6mo', '5d').\n",
    "        interval (str): The data interval (e.g., '1d', '1wk', '1mo').\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing historical stock prices.\n",
    "    \"\"\"\n",
    "    # Fetch data from Yahoo Finance\n",
    "    stock_data = yf.download(symbol, period=period, interval=interval)\n",
    "\n",
    "    return stock_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_log_returns(close: np.ndarray, period: int = 1) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calculate the log returns of the given 'Close' prices.\n",
    "\n",
    "    Parameters:\n",
    "        close (np.ndarray): Array of closing prices.\n",
    "        period (int): The period over which to calculate log returns (default is 1).\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Array of log returns.\n",
    "    \"\"\"\n",
    "    # Shift the array using np.roll (circular shift)\n",
    "    shifted = np.roll(close, period)\n",
    "\n",
    "    # Set the first 'period' values to NaN since they don't have previous values\n",
    "    shifted[:period] = np.nan\n",
    "\n",
    "    # Calculate log returns\n",
    "    log_returns = np.log(close / shifted)\n",
    "    \n",
    "    return log_returns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_ta as ta\n",
    "\n",
    "def calculate_technical_indicators(df: pd.DataFrame) -> dict:\n",
    "    \"\"\"\n",
    "    Calculate technical indicators and return them as NumPy arrays.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame containing historical stock prices.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary with technical indicators as NumPy arrays.\n",
    "    \"\"\"\n",
    "    indicators = {}\n",
    "\n",
    "    # Calculate RSI (Relative Strength Index)\n",
    "    indicators['rsi'] = ta.rsi(df['Close'], length=14).to_numpy()\n",
    "\n",
    "    # Calculate 20-day Exponential Moving Average (EMA)\n",
    "    indicators['ema_20'] = ta.ema(df['Close'], length=20).to_numpy()\n",
    "\n",
    "    # Calculate ADX (Average Directional Index)\n",
    "    adx_df = ta.adx(df['High'], df['Low'], df['Close'], length=14)\n",
    "    indicators['adx'] = adx_df['ADX_14'].to_numpy()\n",
    "\n",
    "    # Calculate VWAP (Volume Weighted Average Price)\n",
    "    vwap_series = ta.vwap(df['High'], df['Low'], df['Close'], df['Volume'])\n",
    "    indicators['vwap'] = vwap_series.to_numpy()\n",
    "\n",
    "    # Calculate normalized volume\n",
    "    indicators['normalized_volume'] = (df['Volume'] / df['Volume'].rolling(window=20).mean()).to_numpy()\n",
    "\n",
    "    return indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import datetime\n",
    "\n",
    "def get_news_articles(stock_symbol: str, api_key: str, from_date: str, to_date: str) -> list:\n",
    "    \"\"\"\n",
    "    Retrieve news articles related to the given stock symbol along with their publication dates.\n",
    "\n",
    "    Parameters:\n",
    "        stock_symbol (str): The stock ticker symbol (e.g., 'AAPL', 'AMZN').\n",
    "        api_key (str): Your NewsAPI API key.\n",
    "        from_date (str): Start date for news retrieval in 'YYYY-MM-DD' format (default: 7 days before today).\n",
    "        to_date (str): End date for news retrieval in 'YYYY-MM-DD' format (default: today's date).\n",
    "\n",
    "    Returns:\n",
    "        list: A list of dictionaries containing article titles, descriptions, and publication dates.\n",
    "    \"\"\"\n",
    "\n",
    "    # Construct the NewsAPI request URL\n",
    "    url = (\n",
    "        f\"https://newsapi.org/v2/everything?q={stock_symbol}&from={from_date}&to={to_date}&\"\n",
    "        f\"sortBy=publishedAt&language=en&apiKey={api_key}\"\n",
    "    )\n",
    "\n",
    "    # Make the API request\n",
    "    response = requests.get(url)\n",
    "    news_data = response.json()\n",
    "\n",
    "    # Extract article details (title, description, date)\n",
    "    articles = [\n",
    "        {\n",
    "            'title': article['title'],\n",
    "            'description': article.get('description', ''),\n",
    "            'publishedAt': article['publishedAt']\n",
    "        }\n",
    "        for article in news_data['articles']\n",
    "    ]\n",
    "\n",
    "    return articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "def add_sentiment_scores_to_articles(articles: list) -> list:\n",
    "    \"\"\"\n",
    "    Add compound sentiment scores to each article dictionary.\n",
    "\n",
    "    Parameters:\n",
    "        articles (list): List of dictionaries containing article titles, descriptions, and publication dates.\n",
    "\n",
    "    Returns:\n",
    "        list: The original list of dictionaries with added 'compound_score' keys.\n",
    "    \"\"\"\n",
    "    # Initialize VADER sentiment analyzer\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "    # Add sentiment scores to each article\n",
    "    for article in articles:\n",
    "        title = article['title'] or \"\"\n",
    "        description = article.get('description', \"\")\n",
    "        text = f\"{title} {description}\"\n",
    "\n",
    "        # Get the compound sentiment score and add it to the article dictionary\n",
    "        article['compound_score'] = analyzer.polarity_scores(text)['compound']\n",
    "\n",
    "    return articles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def articles_to_sentiment_arr(articles: list) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Convert a list of articles with sentiment scores into a NumPy array.\n",
    "\n",
    "    Parameters:\n",
    "        articles (list): List of dictionaries with 'publishedAt' and 'compound_score' keys.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Array of average compound sentiment scores grouped by whole dates.\n",
    "    \"\"\"\n",
    "    # Prepare data for the DataFrame\n",
    "    sentiment_data = [\n",
    "        {'date': article['publishedAt'].split('T')[0], 'compound_score': article['compound_score']}\n",
    "        for article in articles\n",
    "    ]\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    sentiment_df = pd.DataFrame(sentiment_data)\n",
    "\n",
    "    # Convert 'date' to datetime format and group by date to calculate average sentiment\n",
    "    sentiment_df['date'] = pd.to_datetime(sentiment_df['date'])\n",
    "    aggregated_sentiment = sentiment_df.groupby(sentiment_df['date'].dt.date).mean()\n",
    "\n",
    "    # Return the average sentiment scores as a NumPy array\n",
    "    return aggregated_sentiment['compound_score'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_secrets import news_api_key\n",
    "\n",
    "# Example usage\n",
    "stock = 'AMZN'\n",
    "period = '1y'\n",
    "interval = '1d'\n",
    "\n",
    "stock_ohlc = get_stock_data(stock, period, interval)\n",
    "log_returns_arr = calculate_log_returns(stock_ohlc['Close'])\n",
    "technical_indicators_dict = calculate_technical_indicators(stock_ohlc)\n",
    "\n",
    "first_date = stock_ohlc.index.min()\n",
    "last_date = stock_ohlc.index.max()\n",
    "\n",
    "article_list = get_news_articles(stock, news_api_key, first_date, last_date)\n",
    "article_list_sent = add_sentiment_scores_to_articles(article_list)\n",
    "\n",
    "aggregated_sentiment_arr = articles_to_sentiment_arr(article_list_sent)\n",
    "\n",
    "stock_df = stock_ohlc\n",
    "stock_df['log_returns'] = log_returns_arr\n",
    "stock_df['rsi'] = technical_indicators_dict['rsi']\n",
    "stock_df['ema_50'] = technical_indicators_dict['ema_50']\n",
    "stock_df['vwap'] = technical_indicators_dict['vwap_series']\n",
    "stock_df['normalized_volume'] = technical_indicators_dict['normalized_volume']\n",
    "stock_df['sentiment_score'] = aggregated_sentiment_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
